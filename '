import csv
import numpy as np
import pandas as pd
import json
from pathlib import Path
import os
import sys
from datetime import datetime
import influxdb_client
from influxdb_client.client.write_api import SYNCHRONOUS


def parseData(file_path,dest_path,filename):
    contents = None
    try:
        with open(file_path, newline='') as fp:
            site, freq_start, step, lat, lon, data = csv.reader(fp,delimiter=' ')
        data = {
                "site": site[0],
                "freq_start": freq_start[0],
                "step": step[0],
                "lat-long": (np.float64(lat[0]),np.float64(lon[0])),
                "data": data
                }
        saveData(filename,dest_path,**data)
    except IOError as e:
        print(e)

def saveData(fname,dest_path,**kwargs):
    
    site = kwargs['site']
    date = kwargs['data'].pop(0)
    rssi = kwargs['data'][0].split(',')
    lat = kwargs['lat-long'][0]
    lon = kwargs['lat-long'][1]
    time = rssi.pop(0)
    try:
        try:
            rssi = np.array(rssi,dtype=np.float64)
            base_freq = np.float16(kwargs['freq_start'])
            step = float(kwargs['step'])/1000.0 # Khz
            step = round(step,2)
            index_freq = np.arange(base_freq,base_freq + (step * len(rssi) ),step)
            index_freq = np.round(index_freq, decimals=2)
            rssi = np.round(rssi, decimals=1)
            df_data = zip(index_freq, rssi)
            df = pd.DataFrame(df_data, columns=["FREQ", "RSSI"])
            print(df)
            # json_record = df.to_json(orient="columns")
            # parsed = json.loads(json_record)
            # json_s = json.dumps(parsed, indent=4)
            # print(json_s)
            pushData(df)
        except ValueError as e:
            print(e)
            
    except ValueError as e:
        print("Skipping existing file..",fname)

def pushData(data):
    bucket = "spectrum_test"
    org = "ASTI"
    token = "3r3tKvsRrs934WQ4LXQ_HmtFhNy01gKVbpvACShUxw5wbS5N4TKAZBa7gFiv8laJEyhC9BS4Op4gdcfrkGT_Eg=="
    url = "http://localhost:8086"

    client = influxdb_client.InfluxDBClient(
            url = url,
            token = token,
            org = org
    )
    
    write_api = client.write_api(write_options=SYNCHRONOUS)
    write_api.write(bucket,record=data, data_frame_measurement_name='spectrum', data_frame_tag_columns=["RSSI"])
    query_api = client.query_api()
    query = " from(bucket:'spectrum_test')\
        |> range(start: -10m)\
        |> filter(fn:(r) => r._measurement == 'spectrum')\
        |> filter(fn:(r) => r._field == 'RSSI' )"
    result = client.qery_api().query(org = org, query = query)
    results = []
    for table in result:
        for record in table.records:
            results.append((record.get_field(), r ecord.get_value()))
    print(results)

    write_api.__del__()
    client.__del__()
    
    

if __name__ == "__main__":
    CWD = Path.cwd() 
    HOME_DIR = CWD.home()
    # DATA_FOLDER = HOME_DIR.joinpath("ED_Data")
    DATA_FOLDER = CWD.joinpath("test_data")
    DEST_PATH = HOME_DIR.joinpath("server","data.hdf5")
    for root, dirs, files in os.walk(str(DATA_FOLDER)):
        for filename in files:
            if filename.endswith(".csv"):
                parseData(str(DATA_FOLDER.joinpath(filename)),str(DEST_PATH),filename)
